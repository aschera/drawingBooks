{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asche\\anaconda3\\envs\\ailab\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from PIL import Image, ImageOps, ImageFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the images directory exists\n",
    "os.makedirs(\"./images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = \"stable_diffusion_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Print the selected device\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://huggingface.co/CompVis/stable-diffusion-v1-4\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from stable_diffusion_model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00,  7.78it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "# Function to check if the model is saved locally and load it\n",
    "def load_model():\n",
    "    if os.path.exists(local_model_path):\n",
    "        print(f\"Loading model from {local_model_path}...\")\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(local_model_path, torch_dtype=torch.float32)\n",
    "    else:\n",
    "        print(f\"Downloading model {model_id}...\")\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32)\n",
    "        # Save the initialized model for future use\n",
    "        pipe.save_pretrained(local_model_path)\n",
    "        print(f\"Model saved to {local_model_path}\")\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "pipe = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that all necessary components are available\n",
    "if not pipe.text_encoder:\n",
    "    print(\"Text encoder model not found. Downloading...\")\n",
    "    pipe.text_encoder = CLIPTextModel.from_pretrained(model_id, subfolder=\"text_encoder\")\n",
    "if not pipe.tokenizer:\n",
    "    print(\"Tokenizer not found. Downloading...\")\n",
    "    pipe.tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder=\"tokenizer\")\n",
    "\n",
    "# Optionally disable the safety checker\n",
    "pipe.safety_checker = None\n",
    "\n",
    "# Move the model to the selected device\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-process image based on style\n",
    "def post_process_image(image, style=\"color\"):\n",
    "    if style == \"black_and_white\":\n",
    "        image = ImageOps.grayscale(image)\n",
    "    elif style == \"outline\":\n",
    "        image = image.convert(\"L\")  # Convert to grayscale\n",
    "        image = image.filter(ImageFilter.FIND_EDGES)  # Find edges to create an outline effect\n",
    "    return image\n",
    "\n",
    "# Generate image based on prompt and apply style\n",
    "def generate_image(prompt, filename, style=\"color\", num_inference_steps=50):\n",
    "    # Assuming pipe is a function that generates an image from a prompt\n",
    "    image = pipe(prompt, num_inference_steps=num_inference_steps).images[0]\n",
    "    image = post_process_image(image, style)\n",
    "    image.save(filename)\n",
    "    print(f\"Image saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompts and styles\n",
    "prompts_and_styles = [\n",
    "    (\"viking children playing outside with a cat near a fire\", \"outline\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [08:37<00:00, 10.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as generated_image_1_outline.png\n"
     ]
    }
   ],
   "source": [
    "# Generate and save images\n",
    "for i, (prompt, style) in enumerate(prompts_and_styles, start=1):\n",
    "    filename = f\"./images/generated_image_{i}_{style}.png\"\n",
    "    generate_image(prompt, filename, style)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
